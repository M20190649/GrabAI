{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta, datetime\n",
    "import math\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "num_core = max(multiprocessing.cpu_count()-1,1)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_datetime, transform_df\n",
    "from utils import prep_holdout_set, get_timespan_15, gen_features, gen_test_features, prep_dataset\n",
    "from utils import TIME_FEATURES, NUM_LABELS, NUM_REQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv('./data_raw/training.csv')\n",
    "\n",
    "df_holdout_raw = pd.read_csv('./data_raw/mock_holdout.csv')\n",
    "\n",
    "cluster_df = pd.read_csv(\"./data_temp/cluster_df.csv\")\n",
    "cluster_df = cluster_df.set_index('geohash6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both sets to create ground truth set for extracting features and labels\n",
    "# when creating train and test set later, it is ensured that test samples are leaked into train set\n",
    "\n",
    "df_raw = pd.concat([df_train_raw, df_holdout_raw], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "NUM_DAYS = max(df_raw['day'])\n",
    "START_DATE = date(2019, 4, 1) # arbitrary value chosen for first day of dataset\n",
    "# April has 30 days, May 31, making up the 61 days in train set\n",
    "\n",
    "parse_datetime(df_raw, START_DATE) # takes a few mins\n",
    "df = transform_df(df_raw, START_DATE, NUM_DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming T is random and multiple for each location\n",
    "# Remove samples from holdout set that cannot be used as T (i.e. last 5 time stamps from holdout set)\n",
    "\n",
    "parse_datetime(df_holdout_raw, START_DATE) # taEkes a min or two\n",
    "last_timestamp = max(df_holdout_raw['datetime'])\n",
    "df_holdout_raw = df_holdout_raw[df_holdout_raw['datetime'] < last_timestamp-timedelta(minutes=60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train_raw, df_raw, last_timestamp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create intermediate holdout set from which to extract holdout features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocessing to generate \"transformed\" holdout set, used to generate test set\n",
    "\n",
    "# frac to speed up, tests show not much difference in performance\n",
    "df_holdout_raw = df_holdout_raw.sample(frac=0.1, random_state=8) # to comment out\n",
    "\n",
    "# Split into partitions for multiprocessing\n",
    "partition_size = math.floor(len(df_holdout_raw.index) / num_core)\n",
    "holdout_partitions = [df_holdout_raw.iloc[i*partition_size:i*partition_size+partition_size,:] for i in range(0, num_core)]\n",
    "\n",
    "# Add remainders after dividing Dataframe\n",
    "if (num_core * partition_size < len(df_holdout_raw.index)): \n",
    "    leftover = df_holdout_raw[num_core * partition_size:]\n",
    "    holdout_partitions[num_core-1] = pd.concat([holdout_partitions[num_core-1], leftover], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "if __name__ == '__main__':\n",
    "    with Pool(num_core) as p:\n",
    "        results =  p.map_async(partial(prep_holdout_set, df=df), holdout_partitions)\n",
    "        p.close()\n",
    "        p.join()\n",
    "\n",
    "dt_holdout = datetime(2019, 5, 20) # arbitrary, value does not matter\n",
    "df_holdout, geohash_holdout = [], []\n",
    "\n",
    "results = [i for i in results.get()]\n",
    "for i in range(len(results)):\n",
    "    df_holdout.append(results[i][0])\n",
    "    geohash_holdout.append(results[i][1])\n",
    "\n",
    "geohash_holdout = sum(geohash_holdout, [])\n",
    "df_holdout = pd.DataFrame(sum(df_holdout, []))\n",
    "df_holdout.columns = pd.date_range(dt_holdout - timedelta(minutes=15 * NUM_REQ), dt_holdout + timedelta(minutes=15 * NUM_LABELS),\n",
    "                         freq=\"15min\")\n",
    "\n",
    "df_holdout['geohash6'] = geohash_holdout\n",
    "df_holdout = df_holdout.set_index('geohash6')\n",
    "dt_holdout_list = df_holdout_raw['datetime']\n",
    "\n",
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models, prepare test feature set and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "round = 1\n",
    "y_pred, labels_list = [], []\n",
    "\n",
    "myFile = open('./models/scaler.bin', 'rb'):\n",
    "scaler = pickle.load(myFile)\n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict T+1 -> T+5\n",
    "for i in range(5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test set\n",
    "    \n",
    "X_holdout, y_holdout = gen_test_features(dt_holdout, df_holdout, geohash_holdout, dt_holdout_list, cluster_df)\n",
    "X_holdout[:] = scaler.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for T+1\n"
     ]
    }
   ],
   "source": [
    "# Load model and predict\n",
    "\n",
    "model = lgb.Booster(model_file='./model/model_%s.txt' % round)\n",
    "\n",
    "print(\"Predicting for T+%s\" % round)\n",
    "\n",
    "y_pred.append(model.predict(X_holdout).tolist())\n",
    "labels_list.append(y_holdout.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update rolling forecast\n",
    "\n",
    "round += 1\n",
    "dt_holdout = dt_holdout + timedelta(minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall holdout rmse: 0.03297407979046895\n"
     ]
    }
   ],
   "source": [
    "#### Calc overall rmse and save predictions\n",
    "\n",
    "rms = math.sqrt(mean_squared_error([item for items in y_pred for item in items], [item for items in labels_list for item in items]))\n",
    "print(\"Overall holdout rmse:\", rms)\n",
    "\n",
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
